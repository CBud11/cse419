{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "SVM TfidfVectorizer"
      ],
      "metadata": {
        "id": "4K_9bggGZ-sI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWNKFJZsSrwc",
        "outputId": "7bf0f9b9-3038-495d-dd58-481b9546add3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.19      0.09      0.12       147\n",
            "     neutral       0.69      0.88      0.77       639\n",
            "    positive       0.86      0.63      0.73       383\n",
            "\n",
            "    accuracy                           0.70      1169\n",
            "   macro avg       0.58      0.53      0.54      1169\n",
            "weighted avg       0.68      0.70      0.68      1169\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "d=pd.read_csv(\"/content/data.csv\")\n",
        "\n",
        "t=d['Sentence'].values\n",
        "l=d['Sentiment'].values\n",
        "tr_d,tt_d,tr_l,tt_l=train_test_split(t,l,test_size=0.2)\n",
        "\n",
        "fe=TfidfVectorizer()\n",
        "fe_tr=fe.fit_transform(tr_d)\n",
        "fe_tt=fe.transform(tt_d)\n",
        "\n",
        "S=SVC()\n",
        "S.fit(fe_tr,tr_l)\n",
        "\n",
        "p=S.predict(fe_tt)\n",
        "\n",
        "print(classification_report(tt_l,p))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVm CountVectorizer"
      ],
      "metadata": {
        "id": "45-ib1nsehaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "d=pd.read_csv(\"/content/data.csv\")\n",
        "\n",
        "t=d['Sentence'].values\n",
        "l=d['Sentiment'].values\n",
        "tr_d,tt_d,tr_l,tt_l=train_test_split(t,l,test_size=0.2)\n",
        "\n",
        "fe=CountVectorizer()\n",
        "fe_tr=fe.fit_transform(tr_d)\n",
        "fe_tt=fe.transform(tt_d)\n",
        "\n",
        "S=SVC()\n",
        "S.fit(fe_tr,tr_l)\n",
        "\n",
        "p=S.predict(fe_tt)\n",
        "\n",
        "print(classification_report(tt_l,p))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM6IPXKZdvdh",
        "outputId": "d63f51ea-1c93-453d-9002-f9c543887546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.34      0.12      0.18       160\n",
            "     neutral       0.69      0.90      0.78       635\n",
            "    positive       0.74      0.56      0.64       374\n",
            "\n",
            "    accuracy                           0.69      1169\n",
            "   macro avg       0.59      0.53      0.53      1169\n",
            "weighted avg       0.66      0.69      0.65      1169\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naibe Bayes TfidVectorizer"
      ],
      "metadata": {
        "id": "X-JMgz-tewao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "d=pd.read_csv(\"/content/data.csv\")\n",
        "\n",
        "t=d['Sentence'].values\n",
        "l=d['Sentiment'].values\n",
        "tr_d,tt_d,tr_l,tt_l=train_test_split(t,l,test_size=0.2)\n",
        "\n",
        "fe=TfidfVectorizer()\n",
        "fe_tr=fe.fit_transform(tr_d)\n",
        "fe_tt=fe.transform(tt_d)\n",
        "\n",
        "S=MultinomialNB()\n",
        "S.fit(fe_tr,tr_l)\n",
        "\n",
        "p=S.predict(fe_tt)\n",
        "\n",
        "print(classification_report(tt_l,p))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMNDhzvAeul5",
        "outputId": "cf86b031-c266-4787-96af-203d6a9f58d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.83      0.03      0.05       176\n",
            "     neutral       0.62      0.98      0.76       613\n",
            "    positive       0.77      0.40      0.53       380\n",
            "\n",
            "    accuracy                           0.65      1169\n",
            "   macro avg       0.74      0.47      0.45      1169\n",
            "weighted avg       0.70      0.65      0.58      1169\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nava Bayes Countectorizer"
      ],
      "metadata": {
        "id": "K5ZM_qiKfC3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "d=pd.read_csv(\"/content/data.csv\")\n",
        "\n",
        "t=d['Sentence'].values\n",
        "l=d['Sentiment'].values\n",
        "tr_d,tt_d,tr_l,tt_l=train_test_split(t,l,test_size=0.2)\n",
        "\n",
        "fe=CountVectorizer()\n",
        "fe_tr=fe.fit_transform(tr_d)\n",
        "fe_tt=fe.transform(tt_d)\n",
        "\n",
        "S=MultinomialNB()\n",
        "S.fit(fe_tr,tr_l)\n",
        "\n",
        "p=S.predict(fe_tt)\n",
        "\n",
        "print(classification_report(tt_l,p))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKemMgtSfF_4",
        "outputId": "5db9ea72-fd89-4bdd-87b1-eb256b65832a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.47      0.34      0.39       185\n",
            "     neutral       0.73      0.84      0.78       615\n",
            "    positive       0.72      0.64      0.68       369\n",
            "\n",
            "    accuracy                           0.70      1169\n",
            "   macro avg       0.64      0.61      0.62      1169\n",
            "weighted avg       0.69      0.70      0.69      1169\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree TfidfVectorizer"
      ],
      "metadata": {
        "id": "sOb4s2iLfTDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "d=pd.read_csv(\"/content/data.csv\")\n",
        "\n",
        "t=d['Sentence'].values\n",
        "l=d['Sentiment'].values\n",
        "tr_d,tt_d,tr_l,tt_l=train_test_split(t,l,test_size=0.2)\n",
        "\n",
        "fe=TfidfVectorizer()\n",
        "fe_tr=fe.fit_transform(tr_d)\n",
        "fe_tt=fe.transform(tt_d)\n",
        "\n",
        "S=DecisionTreeClassifier()\n",
        "S.fit(fe_tr,tr_l)\n",
        "\n",
        "p=S.predict(fe_tt)\n",
        "\n",
        "print(classification_report(tt_l,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA5RyeJIfZQX",
        "outputId": "5886fb48-ebf9-4bbf-fbfa-7622e8f5c577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.18      0.19      0.18       187\n",
            "     neutral       0.64      0.65      0.64       609\n",
            "    positive       0.64      0.59      0.62       373\n",
            "\n",
            "    accuracy                           0.56      1169\n",
            "   macro avg       0.49      0.48      0.48      1169\n",
            "weighted avg       0.56      0.56      0.56      1169\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree CuntVectorizer"
      ],
      "metadata": {
        "id": "pn1K8EDQhNP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "d=pd.read_csv(\"/content/data.csv\")\n",
        "\n",
        "t=d['Sentence'].values\n",
        "l=d['Sentiment'].values\n",
        "tr_d,tt_d,tr_l,tt_l=train_test_split(t,l,test_size=0.2)\n",
        "\n",
        "fe=CountVectorizer()\n",
        "fe_tr=fe.fit_transform(tr_d)\n",
        "fe_tt=fe.transform(tt_d)\n",
        "\n",
        "S=DecisionTreeClassifier()\n",
        "S.fit(fe_tr,tr_l)\n",
        "\n",
        "p=S.predict(fe_tt)\n",
        "\n",
        "print(classification_report(tt_l,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FjIqRpBgrR6",
        "outputId": "90840df1-2a63-4ae8-bad7-5524ec4ac7b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.19      0.19      0.19       177\n",
            "     neutral       0.65      0.70      0.67       603\n",
            "    positive       0.68      0.60      0.64       389\n",
            "\n",
            "    accuracy                           0.59      1169\n",
            "   macro avg       0.50      0.49      0.50      1169\n",
            "weighted avg       0.59      0.59      0.59      1169\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest TfidfVectorizer"
      ],
      "metadata": {
        "id": "pId8YOaxhlLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "d=pd.read_csv(\"/content/data.csv\")\n",
        "\n",
        "t=d['Sentence'].values\n",
        "l=d['Sentiment'].values\n",
        "tr_d,tt_d,tr_l,tt_l=train_test_split(t,l,test_size=0.2)\n",
        "\n",
        "fe=TfidfVectorizer()\n",
        "fe_tr=fe.fit_transform(tr_d)\n",
        "fe_tt=fe.transform(tt_d)\n",
        "\n",
        "S=RandomForestClassifier()\n",
        "S.fit(fe_tr,tr_l)\n",
        "\n",
        "p=S.predict(fe_tt)\n",
        "\n",
        "print(classification_report(tt_l,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxvncyqFhsRR",
        "outputId": "9a5d1653-9944-4381-bc89-bca80980db28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.17      0.10      0.13       172\n",
            "     neutral       0.65      0.83      0.73       619\n",
            "    positive       0.77      0.56      0.65       378\n",
            "\n",
            "    accuracy                           0.63      1169\n",
            "   macro avg       0.53      0.50      0.50      1169\n",
            "weighted avg       0.62      0.63      0.61      1169\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randm Forest CountVectorizer"
      ],
      "metadata": {
        "id": "3PRzgX8fiuYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "d=pd.read_csv(\"/content/data.csv\")\n",
        "\n",
        "t=d['Sentence'].values\n",
        "l=d['Sentiment'].values\n",
        "tr_d,tt_d,tr_l,tt_l=train_test_split(t,l,test_size=0.2)\n",
        "\n",
        "fe=CountVectorizer()\n",
        "fe_tr=fe.fit_transform(tr_d)\n",
        "fe_tt=fe.transform(tt_d)\n",
        "\n",
        "S=RandomForestClassifier()\n",
        "S.fit(fe_tr,tr_l)\n",
        "\n",
        "p=S.predict(fe_tt)\n",
        "\n",
        "print(classification_report(tt_l,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVKe9yk1ibnR",
        "outputId": "8cab02e7-315a-4ba0-b918-cdf3033833c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.14      0.09      0.11       154\n",
            "     neutral       0.67      0.83      0.74       624\n",
            "    positive       0.80      0.61      0.69       391\n",
            "\n",
            "    accuracy                           0.66      1169\n",
            "   macro avg       0.54      0.51      0.51      1169\n",
            "weighted avg       0.64      0.66      0.64      1169\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi Layer Perceptron TfidfVectorizer"
      ],
      "metadata": {
        "id": "wW-WGVnPi5hC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "d=pd.read_csv(\"/content/data.csv\")\n",
        "\n",
        "t=d['Sentence'].values\n",
        "l=d['Sentiment'].values\n",
        "tr_d,tt_d,tr_l,tt_l=train_test_split(t,l,test_size=0.2)\n",
        "\n",
        "fe=TfidfVectorizer()\n",
        "fe_tr=fe.fit_transform(tr_d)\n",
        "fe_tt=fe.transform(tt_d)\n",
        "\n",
        "S=MLPClassifier()\n",
        "S.fit(fe_tr,tr_l)\n",
        "\n",
        "p=S.predict(fe_tt)\n",
        "\n",
        "print(classification_report(tt_l,p))"
      ],
      "metadata": {
        "id": "ao6l7TnAjAGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi Layer Perceptron CountVectorizer"
      ],
      "metadata": {
        "id": "3pvzmCiIjiaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "d=pd.read_csv(\"/content/data.csv\")\n",
        "\n",
        "t=d['Sentence'].values\n",
        "l=d['Sentiment'].values\n",
        "tr_d,tt_d,tr_l,tt_l=train_test_split(t,l,test_size=0.2)\n",
        "\n",
        "fe=CountVectorizer()\n",
        "fe_tr=fe.fit_transform(tr_d)\n",
        "fe_tt=fe.transform(tt_d)\n",
        "\n",
        "S=MLPClassifier()\n",
        "S.fit(fe_tr,tr_l)\n",
        "\n",
        "p=S.predict(fe_tt)\n",
        "\n",
        "print(classification_report(tt_l,p))"
      ],
      "metadata": {
        "id": "K-D2a1rijoGy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}